{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":150545,"sourceType":"datasetVersion","datasetId":70909},{"sourceId":1637108,"sourceType":"datasetVersion","datasetId":967819},{"sourceId":2487743,"sourceType":"datasetVersion","datasetId":1505882},{"sourceId":3895868,"sourceType":"datasetVersion","datasetId":2314419},{"sourceId":4206335,"sourceType":"datasetVersion","datasetId":2479743},{"sourceId":6057321,"sourceType":"datasetVersion","datasetId":3466024},{"sourceId":7175407,"sourceType":"datasetVersion","datasetId":3885504},{"sourceId":7183441,"sourceType":"datasetVersion","datasetId":4152384},{"sourceId":7424766,"sourceType":"datasetVersion","datasetId":4320051}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# data_prep.py\nimport os, re\nimport pandas as pd\nfrom PIL import Image\n\nDATASET_FOLDERS = {\n    \"mustard\": \"/kaggle/input/900-mustard-leaf-dataset\",\n    \"cauliflower\": \"/kaggle/input/cauliflower-dataset\",\n    \"maize1\": \"/kaggle/input/corn-or-maize-leaf-disease-dataset\",\n    \"maize2\": \"/kaggle/input/maize-disease-dataset\",\n    \"eggplant\": \"/kaggle/input/eggplant-disease-recognition-dataset\",\n    \"plantvillage\": \"/kaggle/input/plantdisease\",\n    \"sugarcane\": \"/kaggle/input/sugarcane-leaf-disease-dataset\",\n    \"wheat\": \"/kaggle/input/wheat-leaf-dataset\",\n    \"rice\": \"/kaggle/input/rice-leaf-diseases-detection\",\n}\n\ndef normalize_name(name):\n    name = name.replace(\" \", \"_\").replace(\"__\", \"_\")\n    name = re.sub(r\"[()]\", \"\", name)\n    return name.strip(\"_\")\n\ndef add_images_from_folder(root_folder, crop_name=None, skip_augmented=True):\n    rows=[]\n    for root, dirs, files in os.walk(root_folder):\n        if skip_augmented and any(\"aug\" in d.lower() for d in root.split(os.sep)):\n            continue\n        for f in files:\n            if f.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n                try:\n                    img = Image.open(os.path.join(root,f)).convert('RGB')\n                except:\n                    continue\n                parent = os.path.basename(root)\n                if crop_name:\n                    crop = crop_name\n                    disease = normalize_name(parent)\n                else:\n                    if \"___\" in parent:\n                        parts = parent.split(\"___\")\n                        crop = normalize_name(parts[0])\n                        disease = normalize_name(\"_\".join(parts[1:]))\n                    else:\n                        crop = normalize_name(parent)\n                        disease = \"unknown\"\n                rows.append({\"path\":os.path.join(root,f),\"crop\":crop,\"disease\":disease})\n    return rows\n\n# Collect all images\nall_rows=[]\n\n# Mustard\nfor subset in [\"TRAIN\",\"TEST\"]:\n    mustard_path = os.path.join(DATASET_FOLDERS[\"mustard\"], subset)\n    if os.path.exists(mustard_path):\n        all_rows += add_images_from_folder(mustard_path, crop_name=\"Mustard\")\n\n# Cauliflower\nall_rows += add_images_from_folder(DATASET_FOLDERS[\"cauliflower\"], crop_name=\"Cauliflower\")\n\n# Maize\nall_rows += add_images_from_folder(DATASET_FOLDERS[\"maize1\"], crop_name=\"Maize\")\nall_rows += add_images_from_folder(DATASET_FOLDERS[\"maize2\"], crop_name=\"Maize\")\n\n# Eggplant\neggplant_root = os.path.join(DATASET_FOLDERS[\"eggplant\"], \"Eggplant Disease Recognition Dataset\")\nfor folder in [\"Original Images\",\"Original Images (Version 02)\"]:\n    folder_path = os.path.join(eggplant_root, folder)\n    if os.path.exists(folder_path):\n        all_rows += add_images_from_folder(folder_path, crop_name=\"Eggplant\")\n\n# PlantVillage\npv_root = os.path.join(DATASET_FOLDERS[\"plantvillage\"], \"PlantVillage\")\nfor folder in os.listdir(pv_root):\n    folder_path = os.path.join(pv_root, folder)\n    if os.path.isdir(folder_path):\n        if folder.lower().startswith(\"tomato\"):\n            all_rows += add_images_from_folder(folder_path, crop_name=\"Tomato\")\n        elif folder.lower().startswith(\"potato\"):\n            all_rows += add_images_from_folder(folder_path, crop_name=\"Potato\")\n        elif folder.lower().startswith(\"pepper\"):\n            all_rows += add_images_from_folder(folder_path, crop_name=\"Pepper\")\n\n# Sugarcane\nall_rows += add_images_from_folder(DATASET_FOLDERS[\"sugarcane\"], crop_name=\"Sugarcane\")\n\n# Wheat\nall_rows += add_images_from_folder(DATASET_FOLDERS[\"wheat\"], crop_name=\"Wheat\")\n\n# Rice\nrice_root = os.path.join(DATASET_FOLDERS[\"rice\"], \"Rice_Leaf_Diease\")\nfor root, dirs, files in os.walk(rice_root):\n    if any(\"aug\" in d.lower() for d in root.split(os.sep)):\n        continue\n    for f in files:\n        if f.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n            all_rows.append({\"path\":os.path.join(root,f),\"crop\":\"Paddy\",\"disease\":normalize_name(os.path.basename(root))})\n\n# Build DataFrame & labels\ndf = pd.DataFrame(all_rows).drop_duplicates().reset_index(drop=True)\ndf[\"disease_label\"] = df[\"crop\"] + \"___\" + df[\"disease\"]\ndf[\"label\"] = pd.factorize(df[\"disease_label\"])[0]\n\n# Save CSV\noutput_csv = \"/kaggle/working/kaggle_dataset_manifest.csv\"\ndf.to_csv(output_csv,index=False)\nprint(f\"Saved {output_csv}\")\nprint(\"Total images:\", len(df))\nprint(\"Num unique classes:\", df['label'].nunique())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport json\n\nIMG_SIZE = (224,224)\nBATCH_SIZE = 32\nEPOCHS_BASE = 10\nEPOCHS_FINE = 15\n\ndf = pd.read_csv(\"/kaggle/working/kaggle_dataset_manifest.csv\")\ntrain_df, temp_df = train_test_split(df, test_size=0.30, stratify=df['label'], random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.50, stratify=temp_df['label'], random_state=42)\n\n# -----------------------------\n# Generators\n# -----------------------------\ndef create_generators(model_name):\n    if model_name==\"EfficientNetB0\":\n        preprocess_func = tf.keras.applications.efficientnet.preprocess_input\n    elif model_name==\"ResNet50\":\n        preprocess_func = tf.keras.applications.resnet.preprocess_input\n    else:\n        preprocess_func = tf.keras.applications.mobilenet_v2.preprocess_input\n\n    train_datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_func,\n        rotation_range=20, width_shift_range=0.1,\n        height_shift_range=0.1, brightness_range=[0.8,1.2],\n        horizontal_flip=True\n    )\n    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n    \n    train_gen = train_datagen.flow_from_dataframe(\n        train_df, x_col='path', y_col='disease_label',\n        target_size=IMG_SIZE, class_mode='categorical',\n        batch_size=BATCH_SIZE, shuffle=True\n    )\n    val_gen = val_datagen.flow_from_dataframe(\n        val_df, x_col='path', y_col='disease_label',\n        target_size=IMG_SIZE, class_mode='categorical',\n        batch_size=BATCH_SIZE, shuffle=False\n    )\n    return train_gen, val_gen\n\n# -----------------------------\n# Build model\n# -----------------------------\ndef build_model(model_name, num_classes):\n    if model_name==\"EfficientNetB0\":\n        base = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE,3))\n    elif model_name==\"ResNet50\":\n        base = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE,3))\n    elif model_name==\"MobileNetV2\":\n        base = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE,3))\n    else:\n        raise ValueError(\"Invalid model name\")\n    \n    x = layers.GlobalAveragePooling2D()(base.output)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    out = layers.Dense(num_classes, activation='softmax')(x)\n    model = models.Model(inputs=base.input, outputs=out)\n    base.trainable = False\n    \n    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n                  loss='categorical_crossentropy', metrics=['accuracy'])\n    return model, base\n\n# -----------------------------\n# Train function\n# -----------------------------\ndef train_model(model_name):\n    print(f\"\\nTraining {model_name}\")\n    train_gen, val_gen = create_generators(model_name)\n    num_classes = len(train_gen.class_indices)\n    model, base = build_model(model_name, num_classes)\n    \n    callbacks = [\n        EarlyStopping(patience=5, restore_best_weights=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n    ]\n    \n    # Base training\n    history_base = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS_BASE, callbacks=callbacks)\n    \n    # Fine-tuning last 50 layers\n    for layer in base.layers[-50:]:\n        layer.trainable = True\n    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n                  loss='categorical_crossentropy', metrics=['accuracy'])\n    history_fine = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS_FINE, callbacks=callbacks)\n    \n    # Save model\n    model_file = f\"{model_name.lower()}_disease_model.h5\"\n    model.save(model_file)\n    print(f\"{model_name} saved as {model_file}\")\n    \n    # Save info for Grad-CAM\n    info = {\n        \"model_file\": model_file,\n        \"last_conv_layer\": base.layers[-1].name,\n        \"class_indices\": train_gen.class_indices,\n        \"history_base\": history_base.history,\n        \"history_fine\": history_fine.history\n    }\n    with open(f\"{model_name.lower()}_info.json\",\"w\") as f:\n        json.dump(info, f)\n    \n    return model_file\n\n# -----------------------------\n# Train all models\n# -----------------------------\nif __name__ == \"__main__\":\n    models_to_train = [\"EfficientNetB0\",\"ResNet50\",\"MobileNetV2\"]\n    for m in models_to_train:\n        train_model(m)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-27T21:22:55.028489Z","iopub.execute_input":"2025-09-27T21:22:55.029165Z","execution_failed":"2025-09-27T21:42:11.475Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport json\n\nIMG_SIZE=(224,224)\nBATCH_SIZE=32\n\ndf = pd.read_csv(\"/kaggle/working/kaggle_dataset_manifest.csv\")\n_, temp_df = train_test_split(df, test_size=0.30, stratify=df['label'], random_state=42)\n_, test_df = train_test_split(temp_df, test_size=0.50, stratify=temp_df['label'], random_state=42)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_gen = test_datagen.flow_from_dataframe(\n    test_df, x_col='path', y_col='disease_label',\n    target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False\n)\n\nmodels_info_files = [\"efficientnetb0_info.json\", \"resnet50_info.json\", \"mobilenetv2_info.json\"]\n\nfor info_file in models_info_files:\n    with open(info_file,\"r\") as f:\n        info = json.load(f)\n\n    model = load_model(info[\"model_file\"])\n    class_indices = info[\"class_indices\"]\n    labels = list(class_indices.keys())\n\n    print(f\"\\nEvaluating {info_file.split('_')[0].capitalize()}...\")\n    preds = model.predict(test_gen)\n    y_true = test_gen.classes\n    y_pred = np.argmax(preds, axis=1)\n\n    # Confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(12,10))\n    sns.heatmap(cm/np.sum(cm), annot=False, cmap='Blues')\n    plt.title(f\"{info_file.split('_')[0].capitalize()} Confusion Matrix (Normalized)\")\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\n    # Classification report\n    print(classification_report(y_true, y_pred, target_names=labels))\n\n    # Training curves\n    history_base = info['history_base']\n    history_fine = info['history_fine']\n\n    acc = history_base['accuracy'] + history_fine['accuracy']\n    val_acc = history_base['val_accuracy'] + history_fine['val_accuracy']\n    loss = history_base['loss'] + history_fine['loss']\n    val_loss = history_base['val_loss'] + history_fine['val_loss']\n\n    plt.figure(figsize=(10,5))\n    plt.plot(acc,label='Train Acc')\n    plt.plot(val_acc,label='Val Acc')\n    plt.plot(loss,label='Train Loss')\n    plt.plot(val_loss,label='Val Loss')\n    plt.title(f\"{info_file.split('_')[0].capitalize()} Training Curves\")\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-27T21:42:11.476Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport cv2\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    \"\"\"\n    Generates Grad-CAM heatmap for given image and model.\n    \"\"\"\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        loss = predictions[:, pred_index]\n\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = np.maximum(heatmap, 0) / (np.max(heatmap) + 1e-10)\n    return heatmap\n\ndef overlay_heatmap(img, heatmap, alpha=0.4):\n    \"\"\"\n    Superimposes heatmap on original image.\n    \"\"\"\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n    heatmap = np.uint8(255*heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    superimposed = cv2.addWeighted(img, 1-alpha, heatmap, alpha, 0)\n    return superimposed\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-27T21:42:11.476Z"},"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_models_dryrun.py\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport json\nimport os\n\n# -----------------------------\n# Config\n# -----------------------------\nIMG_SIZE = (224,224)\nBATCH_SIZE = 16           # smaller for dry-run\nEPOCHS_BASE = 5           # short dry-run\nEPOCHS_FINE = 5\nDRY_RUN_FRACTION = 0.15   # 15% of dataset for quick testing\nMODELS_TO_TRAIN = [\"EfficientNetB0\", \"ResNet50\", \"MobileNetV2\"]\n\n# -----------------------------\n# Load Dataset & Subset\n# -----------------------------\ndf = pd.read_csv(\"/kaggle/working/kaggle_dataset_manifest.csv\")\ndf_sample, _ = train_test_split(df, test_size=1-DRY_RUN_FRACTION, stratify=df['label'], random_state=42)\n\ntrain_df, temp_df = train_test_split(df_sample, test_size=0.30, stratify=df_sample['label'], random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.50, stratify=temp_df['label'], random_state=42)\n\nprint(f\"Dry-run dataset size: {len(df_sample)}, Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n\n# -----------------------------\n# Generators\n# -----------------------------\ndef create_generators(model_name):\n    if model_name==\"EfficientNetB0\":\n        preprocess_func = tf.keras.applications.efficientnet.preprocess_input\n    elif model_name==\"ResNet50\":\n        preprocess_func = tf.keras.applications.resnet.preprocess_input\n    else:\n        preprocess_func = tf.keras.applications.mobilenet_v2.preprocess_input\n\n    train_datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_func,\n        rotation_range=20, width_shift_range=0.1, height_shift_range=0.1,\n        brightness_range=[0.8,1.2], horizontal_flip=True\n    )\n    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_func)\n\n    train_gen = train_datagen.flow_from_dataframe(\n        train_df, x_col='path', y_col='disease_label',\n        target_size=IMG_SIZE, class_mode='categorical',\n        batch_size=BATCH_SIZE, shuffle=True\n    )\n    val_gen = val_datagen.flow_from_dataframe(\n        val_df, x_col='path', y_col='disease_label',\n        target_size=IMG_SIZE, class_mode='categorical',\n        batch_size=BATCH_SIZE, shuffle=False\n    )\n    return train_gen, val_gen\n\n# -----------------------------\n# Build Model\n# -----------------------------\ndef build_model(model_name, num_classes):\n    if model_name==\"EfficientNetB0\":\n        base = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE,3))\n    elif model_name==\"ResNet50\":\n        base = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE,3))\n    elif model_name==\"MobileNetV2\":\n        base = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE,3))\n    else:\n        raise ValueError(\"Invalid model name\")\n    \n    x = layers.GlobalAveragePooling2D()(base.output)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    out = layers.Dense(num_classes, activation='softmax')(x)\n    model = models.Model(inputs=base.input, outputs=out)\n    base.trainable = False\n    \n    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n                  loss='categorical_crossentropy', metrics=['accuracy'])\n    return model, base\n\n# -----------------------------\n# Plot Training Curves\n# -----------------------------\ndef plot_training(history_base, history_fine, model_name):\n    acc = history_base['accuracy'] + history_fine['accuracy']\n    val_acc = history_base['val_accuracy'] + history_fine['val_accuracy']\n    loss = history_base['loss'] + history_fine['loss']\n    val_loss = history_base['val_loss'] + history_fine['val_loss']\n\n    plt.figure(figsize=(12,5))\n    plt.subplot(1,2,1)\n    plt.plot(acc,label='Train Acc')\n    plt.plot(val_acc,label='Val Acc')\n    plt.title(f\"{model_name} Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n\n    plt.subplot(1,2,2)\n    plt.plot(loss,label='Train Loss')\n    plt.plot(val_loss,label='Val Loss')\n    plt.title(f\"{model_name} Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n\n# -----------------------------\n# Confusion Matrix\n# -----------------------------\ndef evaluate_model(model, test_df, class_indices, model_name):\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    test_gen = test_datagen.flow_from_dataframe(\n        test_df, x_col='path', y_col='disease_label',\n        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False\n    )\n    preds = model.predict(test_gen)\n    y_true = test_gen.classes\n    y_pred = np.argmax(preds, axis=1)\n    labels = list(class_indices.keys())\n\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(12,10))\n    sns.heatmap(cm/np.sum(cm), annot=False, cmap='Blues')\n    plt.title(f\"{model_name} Confusion Matrix (Normalized)\")\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\n    print(classification_report(y_true, y_pred, target_names=labels))\n\n# -----------------------------\n# Train All Models (Dry Run)\n# -----------------------------\ndef train_all_models():\n    trained_models_info = {}\n    for model_name in MODELS_TO_TRAIN:\n        print(f\"\\n===== Training {model_name} (Dry Run) =====\")\n        train_gen, val_gen = create_generators(model_name)\n        num_classes = len(train_gen.class_indices)\n        model, base = build_model(model_name, num_classes)\n\n        callbacks = [\n            EarlyStopping(patience=3, restore_best_weights=True),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n        ]\n\n        # Base training\n        history_base = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS_BASE, callbacks=callbacks)\n\n        # Fine-tuning last 50 layers\n        for layer in base.layers[-50:]:\n            layer.trainable = True\n        model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n                      loss='categorical_crossentropy', metrics=['accuracy'])\n        history_fine = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS_FINE, callbacks=callbacks)\n\n        # Save model & info\n        model_file = f\"{model_name.lower()}_dryrun_model.h5\"\n        model.save(model_file)\n        info = {\n            \"model_file\": model_file,\n            \"last_conv_layer\": base.layers[-1].name,\n            \"class_indices\": train_gen.class_indices,\n            \"history_base\": history_base.history,\n            \"history_fine\": history_fine.history\n        }\n        with open(f\"{model_name.lower()}_dryrun_info.json\",\"w\") as f:\n            json.dump(info, f)\n\n        # Plot curves & evaluate\n        plot_training(history_base, history_fine, model_name)\n        evaluate_model(model, test_df, train_gen.class_indices, model_name)\n\n        trained_models_info[model_name] = info\n\n    return trained_models_info\n\n# -----------------------------\n# Run Dry-Run Training\n# -----------------------------\nif __name__ == \"__main__\":\n    trained_models_info = train_all_models()\n    print(\"Dry-run complete for all models.\")\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null}]}